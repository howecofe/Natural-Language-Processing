{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Jiyun Lee - _13 트랜스포머 (Transformer).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6PQSnsGeA2OH"},"source":["# 트랜스포머 (Transformer)\n","\n","* 참고: https://wikidocs.net/31379"]},{"cell_type":"markdown","metadata":{"id":"nbQ-h_XxBAiq"},"source":["* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n","* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n","* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RDiFPIdUBBS2"},"source":["## 포지셔널 인코딩"]},{"cell_type":"markdown","metadata":{"id":"rLqHf_4SEWoa"},"source":["* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n","* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n","* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n","* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"]},{"cell_type":"code","metadata":{"id":"SiO5c_HIFBAk","executionInfo":{"status":"ok","timestamp":1604401262941,"user_tz":-540,"elapsed":862,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def positional_encoding(dim, sentence_length):\n","  encoded_vec = np.array([pos / np.power(10000, 2 * i / dim) for pos in range(sentence_length) for i in range(dim)])\n","  encoded_vec[::2] = np.sin(encoded_vec[::2])\n","  encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n","  return tf.constant(encoded_vec.reshape([sentence_length, dim]), dtype=tf.float32)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"099gUUxhAgy3"},"source":["## 레이어 정규화"]},{"cell_type":"markdown","metadata":{"id":"XCdips98yPuH"},"source":["*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n","*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"]},{"cell_type":"code","metadata":{"id":"TSJjxF86Aeg3","executionInfo":{"status":"ok","timestamp":1604401263314,"user_tz":-540,"elapsed":1229,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def layer_norm(inputs, eps=1e-6):\n","  feature_shape = inputs.get_shape()[-1:]\n","  mean = tf.keras.backend.mean(inputs, [-1], keepdims=True)\n","  std = tf.keras.backend.std(inputs, [-1], keepdims=True)\n","  beta = tf.Variable(tf.zeros(feature_shape), trainable=False)\n","  gamma = tf.Variable(tf.ones(feature_shape), trainable=False)\n","  return gamma * (inputs - mean) / (std + eps) + beta"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"km9ORxIun-MU","executionInfo":{"status":"ok","timestamp":1604401263317,"user_tz":-540,"elapsed":1227,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def sublayer_connection(inputs, sublayer, dropout=0.2):\n","  outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n","  return outputs"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ppb7IxJ3diMC"},"source":["## 어텐션"]},{"cell_type":"markdown","metadata":{"id":"1JaU6MHgy9V2"},"source":["\n","\n","*   트랜스포머 모델의 핵심이 되는 부분\n","*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n","  1.   multi-head attention\n","      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n","      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n","      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n","  2.   self attention\n","      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n","      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n","      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n","      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n","\n","\n","\n","\n","*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kRyL0KDXi6ej"},"source":["### scaled-dot product attention 구현"]},{"cell_type":"markdown","metadata":{"id":"6HtmcgRR3Cr-"},"source":["* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n","* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n","* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"]},{"cell_type":"code","metadata":{"id":"ALEMzi4fdiSQ","executionInfo":{"status":"ok","timestamp":1604401263321,"user_tz":-540,"elapsed":1227,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def scaled_dot_product_attention(query, key, value, masked=False):\n","  key_dim_size = float(key.get_shape().as_list()[-1])\n","  key = tf.transpose(key, perm=[0, 2, 1])\n","\n","  outputs = tf.matmul(query, key) / tf.sqrt(key_dim_size)\n","\n","  if masked:\n","    diag_vals = tf.ones_like(outputs[0, :, :])\n","    tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()\n","    masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1])\n","    paddings = tf.ones_like(masks)*(-2**30)\n","    outputs = tf.where(tf.equal(masks, 0), paddings, outputs)\n","\n","  attention_map = tf.nn.softmax(outputs)\n","  return tf.matmul(attention_map, value)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yr20BxvVi-8b"},"source":["### multi-head attention 구현"]},{"cell_type":"markdown","metadata":{"id":"Gb5qflUH14-H"},"source":["* multi-head attention의 구현 과정\n","  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n","  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n","  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n","  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ooc3FAdQi_Gz","executionInfo":{"status":"ok","timestamp":1604401263324,"user_tz":-540,"elapsed":1227,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def multi_head_attention(query, key, value, num_units, heads, masked=False):\n","  query = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(query)\n","  key = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(key)\n","  value = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(value)\n","\n","  query = tf.concat(tf.split(query, heads, axis=-1), axis=0)\n","  key = tf.concat(tf.split(key, heads, axis=-1), axis=0)\n","  value = tf.concat(tf.split(value, heads, axis=-1), axis=0)\n","\n","  attention_map = scaled_dot_product_attention(query, key, value, masked)\n","  attn_outputs = tf.concat(tf.split(attention_map, heads, axis=0), axis=-1)\n","  attn_outputs = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(attn_outputs)\n","\n","  return attn_outputs"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78Zn5-fYITD4"},"source":["## 포지션-와이즈 피드 포워드 신경망"]},{"cell_type":"markdown","metadata":{"id":"-xxeG2xvo3ZN"},"source":["\n","\n","*   multi-head attention의 결과인 행렬을 입력받아 연산\n","*   일반적인 완전 연결 신경망(Dense layer)를 사용\n","*   position-wise FFNN은 인코더와 디코더에 모두 존재\n","\n"]},{"cell_type":"code","metadata":{"id":"0tSFd5OaITJ0","executionInfo":{"status":"ok","timestamp":1604401263326,"user_tz":-540,"elapsed":1225,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def feed_forward(inputs, num_units):\n","  feature_shape = inputs.get_shape()[-1]\n","  inner_layer = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(inputs)\n","  outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n","  return outputs"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuccViYgBK6v"},"source":["## 인코더\n"]},{"cell_type":"markdown","metadata":{"id":"tG3MH0n1JVLz"},"source":["* 인코더는 하나의 어텐션을 사용\n","  + encoder self-attention (multi-head self-attention과 동일)"]},{"cell_type":"code","metadata":{"id":"m5T0pzBoAnn3","executionInfo":{"status":"ok","timestamp":1604401263329,"user_tz":-540,"elapsed":1223,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def encoder_module(inputs, model_dim, ffn_dim, heads):\n","  self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n","  outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n","  return outputs\n","\n","def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n","  outputs = inputs\n","  for i in range(num_layers):\n","    outputs = encoder_module(outputs, model_dim, ffn_dim, heads)\n","\n","  return outputs"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lcgHRcTEBQqg"},"source":["## 디코더"]},{"cell_type":"markdown","metadata":{"id":"cNj-6FLQwT4-"},"source":["* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n","  1. masked decoder self-attention\n","  2. encoder-decoder attention\n","  3. position-wise FFNN\n","\n","* 디코더에서는 2종류의 어텐션을 사용\n","  1.   masked decoder self-attention\n","    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n","    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n","    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n","  2.   encoder-decoder attention\n","    *   앞서 설명한 multi-head attention과 동일\n","\n"]},{"cell_type":"code","metadata":{"id":"2B05wr7aARcT","executionInfo":{"status":"ok","timestamp":1604401263331,"user_tz":-540,"elapsed":1221,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n","  masked_self_attn = sublayer_connection(inputs,\n","                                         multi_head_attention(inputs, inputs, inputs,\n","                                                              model_dim, heads, masked=True))\n","  self_attn = sublayer_connection(masked_self_attn,\n","                                  multi_head_attention(masked_self_attn,\n","                                                       encoder_outputs,\n","                                                       encoder_outputs,\n","                                                       model_dim, heads))\n","  outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n","  return outputs\n","\n","def decoder(inputs, encoder_outputs, model_dim, ffn_dim, heads, num_layers):\n","  outputs = inputs\n","  for i in range(num_layers):\n","    outputs = decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n","\n","  return outputs"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EtztlyUB1ERS"},"source":["## 트랜스포머를 활용한 챗봇"]},{"cell_type":"markdown","metadata":{"id":"6CGUIAzv6eWs"},"source":["### konlpy 라이브러리"]},{"cell_type":"markdown","metadata":{"id":"Ae0mHT49v5gy"},"source":["*    한글을 처리하기 위해 konlpy 라이브러리 설치"]},{"cell_type":"code","metadata":{"id":"U8yf75uG6hBW","executionInfo":{"status":"ok","timestamp":1604401269904,"user_tz":-540,"elapsed":7760,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"2479b4d0-8f2d-4df5-ecdb-1568c360b17a","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install konlpy"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 55.6MB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 10.1MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, tweepy, beautifulsoup4, colorama, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rUMXvK5H1G9H"},"source":["### 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"miXrjR316mNb"},"source":["* 처리에 필요한 각종 변수 선언\n","* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n","\n"]},{"cell_type":"code","metadata":{"id":"SMjn5PfE1GZR","executionInfo":{"status":"ok","timestamp":1604401269909,"user_tz":-540,"elapsed":7725,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["import re\n","import tensorflow as tf\n","\n","filters = \"([~.,!?\\\"':;)(])\"\n","PAD = '<PADDING>'\n","STD = '<START>'\n","END = '<END>'\n","UNK = '<UNKNOWN>'\n","\n","PAD_INDEX = 0\n","STD_INDEX = 1\n","END_INDEX = 2\n","UNK_INDEX = 3\n","\n","MARKER = [PAD, STD, END, UNK]\n","CHANGE_FILTER = re.compile(filters)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmRFuH2r6oNJ"},"source":["* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"CmrmdXkePWYb","executionInfo":{"status":"ok","timestamp":1604401270423,"user_tz":-540,"elapsed":8228,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","def load_data(data_path):\n","  data_df = pd.read_csv(data_path, header=0)\n","  question, answer = list(data_df['Q']), list(data_df['A'])\n","  train_input, eval_input, train_label, eval_label = train_test_split(question, answer,\n","                                                                      test_size=0.33,\n","                                                                      random_state=111)\n","  return train_input, train_label, eval_input, eval_label"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHuOJHPtPXqq"},"source":["* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"]},{"cell_type":"code","metadata":{"id":"QtQL-AP06oSa","executionInfo":{"status":"ok","timestamp":1604401270424,"user_tz":-540,"elapsed":8223,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def load_vocabulary(data_path):\n","  data_df = pd.read_csv(data_path, encoding='utf-8')\n","  question, answer = list(data_df['Q']), list(data_df['A'])\n","  if tokenize_as_morph:\n","    question = prepro_like_morphlized(question)\n","    answer = prepro_like_morphlized(answer)\n","\n","  data = []\n","  data.extend(question)\n","  data.extend(answer)\n","  words = data_tokenizer(data)\n","  words = list(set(words))\n","  words[:0] = MARKER\n","\n","  char2idx = {char:idx for idx, char in enumerate(words)}\n","  idx2char = {idx:char for idx, char in enumerate(words)}\n","  return char2idx, idx2char, len(char2idx)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5wYtpjv76r5q"},"source":["* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"-bQ3FOva6tg6","executionInfo":{"status":"ok","timestamp":1604401270427,"user_tz":-540,"elapsed":8217,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["from konlpy.tag import Okt\n","\n","def prepro_like_morphlized(data):\n","  morph_analyzer = Okt()\n","  result_data = list()\n","  for seq in data:\n","    morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n","    result_data.append(morphlized_seq)\n","  return result_data"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vhsVp4pWPTR3"},"source":["* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"]},{"cell_type":"code","metadata":{"id":"otLI_RUfPR_g","executionInfo":{"status":"ok","timestamp":1604401270428,"user_tz":-540,"elapsed":8204,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def data_tokenizer(data):\n","  words = []\n","  for sentence in data:\n","    sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n","    for word in sentence.split():\n","      words.append(word)\n","  return [word for word in words if word]"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OkKPA-Mx6uaC"},"source":["* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"jK-yeSThPGsa","executionInfo":{"status":"ok","timestamp":1604401270429,"user_tz":-540,"elapsed":8194,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["import numpy as np\n","\n","def enc_processing(value, dictionary):\n","  sequences_input_index = []\n","  sequences_length = []\n","\n","  if tokenize_as_morph:\n","    value = prepro_like_morphlized(value)\n","\n","  for sequence in value:\n","    sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","    sequence_index = []\n","    for word in sequence.split():\n","      if dictionary.get(word) is not None:\n","        sequence_index.extend([dictionary[word]])\n","      else:\n","        sequence_index.extend([dictionary[UNK]])\n","    if len(sequence_index) > max_len:\n","      sequence_index = sequence_index[:max_len]\n","    sequences_length.append(len(sequence_index))\n","    sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","    sequences_input_index.append(sequence_index)\n","  return np.asarray(sequences_input_index), sequences_length"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4mM57_FPIg7"},"source":["* decoder의 입력을 구성하기 위한 함수 `dec_input_processing()` 선언"]},{"cell_type":"code","metadata":{"id":"cX_NpcTq6vw6","executionInfo":{"status":"ok","timestamp":1604401270430,"user_tz":-540,"elapsed":8186,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def dec_output_processing(value, dictionary):\n","  sequences_output_index = []\n","  sequences_length = []\n","\n","  if tokenize_as_morph:\n","    value = prepro_like_morphlized(value)\n","\n","  for sequence in value:\n","    sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","    sequence_index = []\n","    sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n","    if len(sequence_index) > max_len:\n","      sequence_index = sequence_index[:max_len]\n","    sequences_length.append(len(sequence_index))\n","    sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","    sequences_output_index.append(sequence_index)\n","  return np.asarray(sequences_output_index), sequences_length"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otsTEt4FPLJX"},"source":["* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"]},{"cell_type":"code","metadata":{"id":"eeP0PWHEPMma","executionInfo":{"status":"ok","timestamp":1604401270432,"user_tz":-540,"elapsed":8180,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def dec_target_processing(value, dictionary):\n","  sequences_target_index = []\n","\n","  if tokenize_as_morph:\n","    value = prepro_like_morphlized(value)\n","\n","  for sequence in value:\n","    sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","    sequence_index = [dictionary[word] for word in sequence.split()]\n","    if len(sequence_index) >= max_len:\n","      sequence_index = sequence_index[:max_len - 1] + [dictionary[END]]\n","    else:\n","      sequence_index += [dictionary[END]]\n","    sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","    sequences_target_index.append(sequence_index)\n","  return np.asarray(sequences_target_index)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tb9vVUng6xDq"},"source":["* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n","* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n","* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n","\n"]},{"cell_type":"code","metadata":{"id":"uAlKV4xF62Uf","executionInfo":{"status":"ok","timestamp":1604402514167,"user_tz":-540,"elapsed":902,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def train_input_fn(train_input_enc, train_output_enc, train_target_dec, batch_size):\n","  dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_input_enc, train_output_enc, train_target_dec))\n","  dataset = dataset.shuffle(buffer_size = len(train_input_enc))\n","  dataset = dataset.batch(batch_size)\n","  dataset = dataset.map(rearrange)\n","  dataset = dataset.repeat()                                                                          \n","  iterator = dataset.make_one_shot_iterator()\n","  return iterator.get_next()\n","\n","def eval_input_fn(eval_input_enc, eval_output_enc, eval_target_dec, batch_size):\n","  dataset = tf.compat.v1.data.Dataset.from_tensor_slices((eval_input_enc, eval_output_enc, eval_target_dec))\n","  dataset = dataset.shuffle(buffer_size = len(eval_input_enc))\n","  dataset = dataset.batch(batch_size)\n","  dataset = dataset.map(rearrange)\n","  dataset = dataset.repeat(1)\n","  iterator = dataset.make_one_shot_iterator()\n","  return iterator.get_next()\n","\n","def rearrange(input, output, target):\n","  features = {'input':input, 'output':output}\n","  return features, target"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"is-GhUDN62xC"},"source":["* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n","* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"]},{"cell_type":"code","metadata":{"id":"jCfwWXhb64Cc","executionInfo":{"status":"ok","timestamp":1604401270436,"user_tz":-540,"elapsed":8169,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def pred2string(value, dictionary):\n","  sentence_string = []\n","  is_finished = False\n","  print(value)\n","\n","  for v in value:\n","    print(v['indexs'])\n","    sentence_string = [dictionary[index] for index in v['indexs']]\n","\n","  answer = \"\"\n","  for word in sentence_string:\n","    if word == END:\n","      is_finished = True\n","      break\n","\n","    if word != PAD and word != END:\n","      answer += word\n","      answer += \" \"\n","\n","  print(answer)\n","  return answer, is_finished"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwp9Nnwz7UoG"},"source":["* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n","* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"]},{"cell_type":"code","metadata":{"id":"-T536MdU7Taq","executionInfo":{"status":"ok","timestamp":1604401349791,"user_tz":-540,"elapsed":87516,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["import pandas as pd\n","\n","tokenize_as_morph = True\n","\n","data_path = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv'\n","\n","char2idx, idx2char, len_vocab = load_vocabulary(data_path)\n","train_input, train_label, eval_input, eval_label = load_data(data_path)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7cVd7AOKinqn"},"source":["### 모델 구성"]},{"cell_type":"markdown","metadata":{"id":"hqLJ0a6r49yi"},"source":["* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"]},{"cell_type":"code","metadata":{"id":"CNeeXoZginvj","executionInfo":{"status":"ok","timestamp":1604401349803,"user_tz":-540,"elapsed":87523,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def model(features, labels, mode, params):\n","  TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n","  EVAL = mode == tf.estimator.ModeKeys.EVAL\n","  PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n","\n","  position_encode = positional_encoding(params['embedding_size'], params['max_len'])\n","  if params['xavier_initializer']:\n","    embedding_initializer = 'glorot_normal'\n","  else:\n","    embedding_initializer = 'uniform'\n","\n","  embedding = tf.keras.layers.Embedding(params['len_vocab'],\n","                                        params['embedding_size'],\n","                                        embeddings_initializer = embedding_initializer)\n","  \n","  x_embedded_matrix = embedding(features['input']) + position_encode\n","  y_embedded_matrix = embedding(features['output']) + position_encode\n","\n","  encoder_outputs = encoder(x_embedded_matrix, params['model_hidden_size'], params['ffn_hidden_size'],\n","                            params['attention_head_size'], params['layer_size'])\n","  decoder_outputs = decoder(y_embedded_matrix, encoder_outputs, params['model_hidden_size'],\n","                            params['ffn_hidden_size'], params['attention_head_size'], params['layer_size'])\n","  \n","  logits = tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n","  predict = tf.argmax(logits, 2)\n","\n","  if PREDICT:\n","    predictions = {'indexs': predict,\n","                   'logits': logits}\n","    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","  \n","  labels_ = tf.one_hot(labels, params['len_vocab'])\n","  loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_))\n","  accuracy = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predict)\n","\n","  metrics = {'accuracy':accuracy}\n","  tf.summary.scalar('accuracy', accuracy[1])\n","\n","  if EVAL:\n","    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n","  assert TRAIN\n","\n","  optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=params['learning_rate'])\n","  train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\n","  return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7PrLEWE1JCs"},"source":["### 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"Gy_Opm_A7DKC"},"source":["*   필요한 각종 인자들을 설정\n","*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"]},{"cell_type":"code","metadata":{"id":"CKGYuqmH6_kj","executionInfo":{"status":"ok","timestamp":1604401349807,"user_tz":-540,"elapsed":87517,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["max_len = 25\n","epoch = 5000\n","batch_size = 256\n","embedding_size = 100\n","model_hidden_size = 100\n","ffn_hidden_size = 100\n","attention_head_size = 100\n","lr = 0.001\n","layer_size = 3\n","xavier_initializer = True"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aaXalEy57ODq"},"source":["*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n","*   평가 데이터에도 동일하게 가공"]},{"cell_type":"code","metadata":{"id":"NWlgWWIq1KSh","executionInfo":{"status":"ok","timestamp":1604401455082,"user_tz":-540,"elapsed":192779,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["train_input_enc, train_input_enc_length = enc_processing(train_input, char2idx)\n","train_output_dec, train_output_dec_length = dec_output_processing(train_label, char2idx)\n","train_target_dec = dec_target_processing(train_label, char2idx)\n","\n","eval_input_enc, eval_input_enc_length = enc_processing(eval_input, char2idx)\n","eval_output_dec, eval_output_dec_length = dec_output_processing(eval_label, char2idx)\n","eval_target_dec = dec_target_processing(eval_label, char2idx)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZGgZzWs7Mr7"},"source":["* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n","* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"]},{"cell_type":"code","metadata":{"id":"B9vjc3Ck7F4J","executionInfo":{"status":"ok","timestamp":1604401455088,"user_tz":-540,"elapsed":192772,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"17368beb-c531-4dc8-dffa-5e0843bc720a","colab":{"base_uri":"https://localhost:8080/"}},"source":["transformer = tf.estimator.Estimator(\n","    model_fn = model,\n","    params = {'embedding_size': embedding_size,\n","              'model_hidden_size': model_hidden_size,\n","              'ffn_hidden_size': ffn_hidden_size,\n","              'attention_head_size': attention_head_size,\n","              'learning_rate': lr,\n","              'len_vocab': len_vocab,\n","              'layer_size': layer_size,\n","              'max_len': max_len,\n","              'xavier_initializer': xavier_initializer}\n",")"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpef1wy20t\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpef1wy20t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wl_pwUiw7INZ"},"source":["* 학습한 모델을 사용해 챗봇을 사용\n","* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n","* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"]},{"cell_type":"code","metadata":{"id":"COO-0PcS7Hy5","executionInfo":{"status":"ok","timestamp":1604402206113,"user_tz":-540,"elapsed":943779,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"39517b4a-5c34-479e-8668-4c829069e77b","colab":{"base_uri":"https://localhost:8080/"}},"source":["transformer.train(input_fn=lambda: train_input_fn(train_input_enc, train_output_dec, train_target_dec, batch_size), steps=epoch)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From <ipython-input-19-2351289eb7ad>:7: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n","INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not pass `graph_parents`.  They will  no longer be used.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n","INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpef1wy20t/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n","INFO:tensorflow:loss = 9.707887, step = 0\n","INFO:tensorflow:global_step/sec: 5.71039\n","INFO:tensorflow:loss = 1.6582632, step = 100 (17.516 sec)\n","INFO:tensorflow:global_step/sec: 7.02833\n","INFO:tensorflow:loss = 1.3774605, step = 200 (14.229 sec)\n","INFO:tensorflow:global_step/sec: 7.05077\n","INFO:tensorflow:loss = 1.1475763, step = 300 (14.183 sec)\n","INFO:tensorflow:global_step/sec: 7.04681\n","INFO:tensorflow:loss = 1.0614498, step = 400 (14.191 sec)\n","INFO:tensorflow:global_step/sec: 7.02138\n","INFO:tensorflow:loss = 0.8405862, step = 500 (14.239 sec)\n","INFO:tensorflow:global_step/sec: 7.04622\n","INFO:tensorflow:loss = 0.74080306, step = 600 (14.194 sec)\n","INFO:tensorflow:global_step/sec: 7.02872\n","INFO:tensorflow:loss = 0.6665831, step = 700 (14.225 sec)\n","INFO:tensorflow:global_step/sec: 7.02962\n","INFO:tensorflow:loss = 0.61927253, step = 800 (14.226 sec)\n","INFO:tensorflow:global_step/sec: 7.01243\n","INFO:tensorflow:loss = 0.51569545, step = 900 (14.262 sec)\n","INFO:tensorflow:global_step/sec: 7.0352\n","INFO:tensorflow:loss = 0.43074372, step = 1000 (14.216 sec)\n","INFO:tensorflow:global_step/sec: 7.03533\n","INFO:tensorflow:loss = 0.3695997, step = 1100 (14.212 sec)\n","INFO:tensorflow:global_step/sec: 7.04902\n","INFO:tensorflow:loss = 0.28042904, step = 1200 (14.184 sec)\n","INFO:tensorflow:global_step/sec: 7.03922\n","INFO:tensorflow:loss = 0.21895844, step = 1300 (14.208 sec)\n","INFO:tensorflow:global_step/sec: 6.99328\n","INFO:tensorflow:loss = 0.1465806, step = 1400 (14.302 sec)\n","INFO:tensorflow:global_step/sec: 7.02421\n","INFO:tensorflow:loss = 0.12088169, step = 1500 (14.232 sec)\n","INFO:tensorflow:global_step/sec: 7.05813\n","INFO:tensorflow:loss = 0.08499584, step = 1600 (14.171 sec)\n","INFO:tensorflow:global_step/sec: 7.04786\n","INFO:tensorflow:loss = 0.06514172, step = 1700 (14.190 sec)\n","INFO:tensorflow:global_step/sec: 7.0454\n","INFO:tensorflow:loss = 0.04540398, step = 1800 (14.192 sec)\n","INFO:tensorflow:global_step/sec: 7.055\n","INFO:tensorflow:loss = 0.035622403, step = 1900 (14.175 sec)\n","INFO:tensorflow:global_step/sec: 7.03822\n","INFO:tensorflow:loss = 0.029033108, step = 2000 (14.207 sec)\n","INFO:tensorflow:global_step/sec: 7.03386\n","INFO:tensorflow:loss = 0.022939, step = 2100 (14.218 sec)\n","INFO:tensorflow:global_step/sec: 7.03241\n","INFO:tensorflow:loss = 0.019853499, step = 2200 (14.218 sec)\n","INFO:tensorflow:global_step/sec: 6.98945\n","INFO:tensorflow:loss = 0.013889824, step = 2300 (14.307 sec)\n","INFO:tensorflow:global_step/sec: 7.0107\n","INFO:tensorflow:loss = 0.010500205, step = 2400 (14.265 sec)\n","INFO:tensorflow:global_step/sec: 6.98523\n","INFO:tensorflow:loss = 0.009629802, step = 2500 (14.317 sec)\n","INFO:tensorflow:global_step/sec: 6.99038\n","INFO:tensorflow:loss = 0.008585999, step = 2600 (14.303 sec)\n","INFO:tensorflow:global_step/sec: 6.98365\n","INFO:tensorflow:loss = 0.0072022704, step = 2700 (14.320 sec)\n","INFO:tensorflow:global_step/sec: 7.00479\n","INFO:tensorflow:loss = 0.006904608, step = 2800 (14.274 sec)\n","INFO:tensorflow:global_step/sec: 6.99062\n","INFO:tensorflow:loss = 0.0062549342, step = 2900 (14.307 sec)\n","INFO:tensorflow:global_step/sec: 6.98877\n","INFO:tensorflow:loss = 0.0062631164, step = 3000 (14.306 sec)\n","INFO:tensorflow:global_step/sec: 6.98819\n","INFO:tensorflow:loss = 0.006522125, step = 3100 (14.312 sec)\n","INFO:tensorflow:global_step/sec: 6.98787\n","INFO:tensorflow:loss = 0.06466144, step = 3200 (14.312 sec)\n","INFO:tensorflow:global_step/sec: 6.99204\n","INFO:tensorflow:loss = 0.01711227, step = 3300 (14.300 sec)\n","INFO:tensorflow:global_step/sec: 7.00788\n","INFO:tensorflow:loss = 0.010232061, step = 3400 (14.270 sec)\n","INFO:tensorflow:global_step/sec: 7.02007\n","INFO:tensorflow:loss = 0.0074567157, step = 3500 (14.246 sec)\n","INFO:tensorflow:global_step/sec: 6.94797\n","INFO:tensorflow:loss = 0.0056450027, step = 3600 (14.392 sec)\n","INFO:tensorflow:global_step/sec: 6.99571\n","INFO:tensorflow:loss = 0.005291506, step = 3700 (14.296 sec)\n","INFO:tensorflow:global_step/sec: 6.99399\n","INFO:tensorflow:loss = 0.004767741, step = 3800 (14.296 sec)\n","INFO:tensorflow:global_step/sec: 7.01319\n","INFO:tensorflow:loss = 0.0043804906, step = 3900 (14.261 sec)\n","INFO:tensorflow:global_step/sec: 7.02802\n","INFO:tensorflow:loss = 0.003585468, step = 4000 (14.227 sec)\n","INFO:tensorflow:global_step/sec: 7.01269\n","INFO:tensorflow:loss = 0.0030387945, step = 4100 (14.260 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4154...\n","INFO:tensorflow:Saving checkpoints for 4154 into /tmp/tmpef1wy20t/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4154...\n","INFO:tensorflow:global_step/sec: 6.59122\n","INFO:tensorflow:loss = 0.0033825906, step = 4200 (15.173 sec)\n","INFO:tensorflow:global_step/sec: 7.0173\n","INFO:tensorflow:loss = 0.0025066135, step = 4300 (14.251 sec)\n","INFO:tensorflow:global_step/sec: 7.00906\n","INFO:tensorflow:loss = 0.0038363105, step = 4400 (14.266 sec)\n","INFO:tensorflow:global_step/sec: 7.01982\n","INFO:tensorflow:loss = 0.00270837, step = 4500 (14.243 sec)\n","INFO:tensorflow:global_step/sec: 7.02545\n","INFO:tensorflow:loss = 0.0022437111, step = 4600 (14.236 sec)\n","INFO:tensorflow:global_step/sec: 7.03009\n","INFO:tensorflow:loss = 0.0021155083, step = 4700 (14.225 sec)\n","INFO:tensorflow:global_step/sec: 7.039\n","INFO:tensorflow:loss = 0.0027643987, step = 4800 (14.206 sec)\n","INFO:tensorflow:global_step/sec: 7.02927\n","INFO:tensorflow:loss = 0.0018192227, step = 4900 (14.228 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n","INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpef1wy20t/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n","INFO:tensorflow:Loss for final step: 0.0018844738.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7efe347c0e80>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"G7WrPjiZ9KCU","executionInfo":{"status":"ok","timestamp":1604402211171,"user_tz":-540,"elapsed":948827,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"8db32f2a-3bb7-4b3f-eaad-a4afaffcae84","colab":{"base_uri":"https://localhost:8080/"}},"source":["eval_result = transformer.evaluate(input_fn=lambda: eval_input_fn(eval_input_enc, eval_output_dec, eval_target_dec, batch_size))\n","print(\"accuracy: {accuracy: 0.3f}\".format(**eval_result))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-11-03T11:16:47Z\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Inference Time : 2.73552s\n","INFO:tensorflow:Finished evaluation at 2020-11-03-11:16:49\n","INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8653921, global_step = 5000, loss = 1.53836\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpef1wy20t/model.ckpt-5000\n","accuracy:  0.865\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MNcrVf2z1LSM"},"source":["### 예측"]},{"cell_type":"markdown","metadata":{"id":"R5lY9DrW8eSK"},"source":["* 학습한 모델을 사용해 챗봇을 사용\n","* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n","* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"]},{"cell_type":"code","metadata":{"id":"N9IQaBx4Qw8J","executionInfo":{"status":"ok","timestamp":1604402579106,"user_tz":-540,"elapsed":1113,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}}},"source":["def chatbot(sentence):\n","  pred_input_enc, pred_input_enc_length = enc_processing([sentence], char2idx)\n","  pred_output_dec, pred_output_dec_length = dec_output_processing([\"\"], char2idx)\n","  pred_target_dec = dec_target_processing([\"\"], char2idx)\n","\n","  for i in range(max_len):\n","    if i > 0:\n","      pred_output_dec, pred_output_dec_length = dec_output_processing([answer], char2idx)\n","      pred_target_dec = dec_target_processing([answer], char2idx)\n","\n","    predictions = transformer.predict(input_fn=lambda: eval_input_fn(pred_input_enc, pred_output_dec, pred_target_dec, 1))\n","\n","    answer, finished = pred2string(predictions, idx2char)\n","\n","    if finished:\n","      break\n","\n","  return answer"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjHZKvJ31MAU","executionInfo":{"status":"ok","timestamp":1604402586169,"user_tz":-540,"elapsed":6392,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"1f627d5e-2849-44b7-bb09-80581d744340","colab":{"base_uri":"https://localhost:8080/","height":399}},"source":["chatbot(\"안녕?\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["<generator object Estimator.predict at 0x7efe33b762b0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[2388    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","안녕하세요 \n","<generator object Estimator.predict at 0x7efe33aec938>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[2388    2    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","안녕하세요 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'안녕하세요 '"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"_mjRZwyLQ_gP","executionInfo":{"status":"ok","timestamp":1604402613469,"user_tz":-540,"elapsed":25227,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"ca590b03-3b10-40d6-aa94-71e07316b469","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["chatbot(\"너 누구냐?\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["<generator object Estimator.predict at 0x7efe33ae8c50>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[734   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0]\n","저 \n","<generator object Estimator.predict at 0x7efe33aec728>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 \n","<generator object Estimator.predict at 0x7efdb4915c50>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  4095     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 위로 \n","<generator object Estimator.predict at 0x7efe33e0f678>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  4095 11350     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 위로 봇 \n","<generator object Estimator.predict at 0x7efe33aec728>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  4095 11350  1087     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 위로 봇 입니다 \n","<generator object Estimator.predict at 0x7efe33e0f678>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  4095 11350  1087     2     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 위로 봇 입니다 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'저 는 위로 봇 입니다 '"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"T7AJCsXRTqJx","executionInfo":{"status":"ok","timestamp":1604402652409,"user_tz":-540,"elapsed":36877,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"afb98695-404d-4321-92a0-e1537067cc7a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["chatbot(\"뭐 먹었어?\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["<generator object Estimator.predict at 0x7efcb25894c0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[734   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0]\n","저 \n","<generator object Estimator.predict at 0x7efdbf08caf0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 \n","<generator object Estimator.predict at 0x7efcb0a43c50>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 \n","<generator object Estimator.predict at 0x7efcb25894c0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039  2037     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 가 \n","<generator object Estimator.predict at 0x7efcb0a43c50>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039  2037  5851     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 가 밥 \n","<generator object Estimator.predict at 0x7efcb25894c0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039  2037  5851  1068     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 가 밥 이 \n","<generator object Estimator.predict at 0x7efcb0a43c50>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039  2037  5851  1068 10216     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 가 밥 이 예요 \n","<generator object Estimator.predict at 0x7efcb25894c0>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[  734 11796  9039  2037  5851  1068 10216     2     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","저 는 배터리 가 밥 이 예요 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'저 는 배터리 가 밥 이 예요 '"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"_M8mfoUfeAWQ","executionInfo":{"status":"ok","timestamp":1604402853827,"user_tz":-540,"elapsed":28321,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"4ec7cb00-00e6-4243-f645-1adbf6882760","colab":{"base_uri":"https://localhost:8080/","height":944}},"source":["chatbot(\"내일 날씨 어때?\")"],"execution_count":42,"outputs":[{"output_type":"stream","text":["<generator object Estimator.predict at 0x7efca6eabe60>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[3607    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","날씨 \n","<generator object Estimator.predict at 0x7efca4955a40>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[3607 1126    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","날씨 어플 \n","<generator object Estimator.predict at 0x7efc9f5a4d58>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[3607 1126 5681    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","날씨 어플 에 \n","<generator object Estimator.predict at 0x7efca6eabe60>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[3607 1126 5681 6806    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","날씨 어플 에 물어보세요 \n","<generator object Estimator.predict at 0x7efc9f5a4d58>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[3607 1126 5681 6806    2    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","날씨 어플 에 물어보세요 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'날씨 어플 에 물어보세요 '"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"P5mrdGRaem6v","executionInfo":{"status":"ok","timestamp":1604402872242,"user_tz":-540,"elapsed":34634,"user":{"displayName":"Jiyun Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpSdwdJBBgYaiIb6qCfAsFUPH1V_9iVFNjCLE=s64","userId":"03630043654938890814"}},"outputId":"b858f416-588a-470d-c55f-396733a97201","colab":{"base_uri":"https://localhost:8080/","height":617}},"source":["chatbot(\"나랑 놀아줘\")"],"execution_count":43,"outputs":[{"output_type":"stream","text":["<generator object Estimator.predict at 0x7efc9e30ebf8>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[6771    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0]\n","같이 \n","<generator object Estimator.predict at 0x7efc9c7729e8>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[ 6771 15105     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","같이 놀아요 \n","<generator object Estimator.predict at 0x7efc9ff10e60>\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpef1wy20t/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[ 6771 15105     2     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0]\n","같이 놀아요 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'같이 놀아요 '"]},"metadata":{"tags":[]},"execution_count":43}]}]}